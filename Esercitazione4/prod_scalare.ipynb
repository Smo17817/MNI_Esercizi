{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c113331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to c:\\users\\simon\\appdata\\local\\temp\\pip-req-build-hgccuuyw\n",
      "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Source files will be saved in \"C:\\Users\\simon\\AppData\\Local\\Temp\\tmpnb7jnwqh\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git 'C:\\Users\\simon\\AppData\\Local\\Temp\\pip-req-build-hgccuuyw'\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b70557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source files will be saved in \"C:\\Users\\simon\\AppData\\Local\\Temp\\tmp7295vof3\".\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa94fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA error in cudaMalloc((void **) &d_u, nBytes) at C:\\Users\\simon\\AppData\\Local\\Temp\\tmp7295vof3\\0c3be197-8bc6-42df-9f52-d28c475815cb\\single_file.cu:51 -> (null)\n",
      "***\t SOMMA DI DUE ARRAY \t***\n",
      "N = 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "#include <assert.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <time.h>\n",
    "#include <string.h>\n",
    "#include <math.h>\n",
    "// Seriale - combina le somme parziali calcolate dai vari thread\n",
    "void sommaCPU(float *a, float *b, float *c, int n){\n",
    "\tfor(int i = 0; i < n; i++)\n",
    "\t\tc[i] = a[i] + b[i];\n",
    "}\n",
    "\n",
    "// Parallelo\n",
    "__global__ void sommaGPU (float* a, float * b, float* c, int n) {\n",
    "\tint index = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "\tif(index < n)\n",
    "\t\tc[index] = a[index] + b[index];\n",
    "}\n",
    "\n",
    "int main (){\n",
    "    float *h_u, *h_v, *h_res, *h_res2;\n",
    "    float *d_u, *d_v, *d_res;\n",
    "    int N, nBytes;\n",
    "    dim3 gridDim, blockDim;\n",
    "    float elapsed; // calcolo del tempo\n",
    "\n",
    "    printf(\"***\\t SOMMA DI DUE ARRAY \\t***\\n\");\n",
    "\n",
    "    printf(\"Inserisci un valore per N: \");\n",
    "    N=4;\n",
    "\n",
    "    nBytes = N * sizeof(float);\n",
    "    h_u = (float *)malloc(nBytes);\n",
    "    h_v = (float *)malloc(nBytes);\n",
    "    h_res = (float *)malloc(nBytes);\n",
    "    h_res2 = (float *)malloc(nBytes);\n",
    "    cudaMalloc((void **) &d_u, nBytes);\n",
    "    cudaMalloc((void **) &d_v, nBytes);\n",
    "    cudaMalloc((void **) &d_res, nBytes);\n",
    "\n",
    "    // la generazione randomica dei vettori segue l'ora attuale del sistema\n",
    "    srand((unsigned int) time(0));\n",
    "\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_u[i] = rand()%5-2;\n",
    "        h_v[i] = rand()%5-2;\n",
    "    }\n",
    "\n",
    "    // i vettori inizializzati vengono copiati dall'host al device\n",
    "    cudaMemcpy(d_u, h_u, nBytes, cudaMemcpyHostToDevice);\n",
    "\tcudaMemcpy(d_v, h_v, nBytes, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // il contenuto del vettore res viene posto a 0 sia in host che device\n",
    "\tmemset(h_res, 0, nBytes);\n",
    "\tcudaMemset(d_res, 0, nBytes);\n",
    "\n",
    "    //configurazione del kernel\n",
    "\tblockDim.x=128;\n",
    "\n",
    "    // la griglia risultante Ã¨ 1D - se il resto !=0 viene distribuito un addendo aggiuntivo\n",
    "\tgridDim.x= N / blockDim.x + (( N % blockDim.x)== 0? 0 : 1);\n",
    "\n",
    "    // calcolo del tempo\n",
    "    cudaEvent_t start, stop;\n",
    "\tcudaEventCreate(&start);\n",
    "\tcudaEventCreate(&stop);\n",
    "\n",
    "\tcudaEventRecord(start);\n",
    "\n",
    "    //invocazione del kernel\n",
    "\tsommaGPU<<<gridDim, blockDim>>>(d_u, d_v, d_res, N);\n",
    "\n",
    "\tcudaEventRecord(stop);\n",
    "    // assicura che tutti siano arrivati all'evento stop prima di registrare il tempo\n",
    "\tcudaEventSynchronize(stop);\n",
    "\n",
    "\n",
    "\t// tempo tra i due eventi in millisecondi\n",
    "\tcudaEventElapsedTime(&elapsed, start, stop);\n",
    "\tcudaEventDestroy(start);\n",
    "\tcudaEventDestroy(stop);\n",
    "\tprintf(\"tempo GPU=%f\\n\", elapsed);\n",
    "\n",
    "    // copia nuovamente il risultato sull'host\n",
    "\tcudaMemcpy(h_res, d_res, nBytes, cudaMemcpyDeviceToHost);\n",
    "\n",
    "\t// calcolo su CPU\n",
    "\tcudaEventCreate(&start);\n",
    "\tcudaEventCreate(&stop);\n",
    "\tcudaEventRecord(start);\n",
    "\n",
    "\t// calcolo somma seriale\n",
    "\tsommaCPU(h_u, h_v, h_res2, N);\n",
    "\n",
    "\tcudaEventRecord(stop);\n",
    "\tcudaEventSynchronize(stop); // assicura che tutti siano arrivati all'evento stop prima di registrare il tempo\n",
    "\tcudaEventElapsedTime(&elapsed, start, stop);\n",
    "\tcudaEventDestroy(start);\n",
    "\tcudaEventDestroy(stop);\n",
    "\tprintf(\"tempo CPU=%f\\n\", elapsed);\n",
    "\n",
    "    for (int i = 0; i < N; i++)\n",
    "        assert(h_res[i] == h_res2[i]);\n",
    "\n",
    "\tif (N < 20) {\n",
    "        // stampa vettore u\n",
    "\t\tfor(int i = 0; i < N; i++)\n",
    "\t\t\tprintf(\"h_u[%d]=%6.2f \", i, h_u[i]);\n",
    "\t\tprintf(\"\\n\");\n",
    "        // stampa vettore v\n",
    "\t\tfor(int i = 0; i < N; i++)\n",
    "\t\t\tprintf(\"h_v[%d]=%6.2f \",i, h_v[i]);\n",
    "        // stampa vettore res\n",
    "\t\tprintf(\"\\n\");\n",
    "\t\tfor(int i = 0; i < N; i++)\n",
    "\t\t\tprintf(\"h_res[%d]=%6.2f \",i, h_res[i]);\n",
    "\t\tprintf(\"\\n\");\n",
    "\t}\n",
    "\tfree(h_u); free(h_v); free(h_res); free(h_res2);\n",
    "\tcudaFree(d_u); cudaFree(d_v); cudaFree(d_res);\n",
    "\treturn 0;\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
